Information About DASH.JS and How It Works:

* How to build a player with NO plugins?
* All browsers support progressive download > Plays it as it's downloading it
* Disadvantages/Liabilities of progressive download:
* 	1. No ability to do adaptive bitrate playback
* 	2. Whole video sits in the browser cache. User can download your content (difficult to protect)
* 	3. Different browsers support different codecs (Less of a problem as of today):
* 		a. H264 (Cisco paid for license to enable this on all browsers)
* 		b. webM (Mostly chrome)
* 		c. VP8/VP9
* 	4. Safari (on iOS & MacOS only) natively support HLS
* 	5. Media Source Extensions (MSE): They give us an API on the <video> tag in HTML
* 		a. With only <video>: You mention a source and it progressively downloads it
* 		b. With MSE: You send audio and video bit by bit to the HTML5 player
* 			i. You can make decisions as you're downloading it, and 
* 			ii. You can write adaptive bitrate algorithms to pick up media of the apt bitrate
* 			iii. Get the right chunk of media and hand it over to browser to play it back
* 			iv. Not universally supported (on all browsers) yet!
* 	6. MSE advantages:
* 		a. Hands over segments to HTML5 video buffer directly
* 		b. Therefore, enables HTTP streaming in HTML (Ex: DASH, HLS)
* 	7. Media Source Extensions (MSE) Support:
* 		a. Chrome
* 		b. IE11+ on windows 8.1+
* 		c. Safari (MacOS only)
* 		d. Firefox (in Beta)
* 	8. Advantages of DASH:
* 		1. Open standard
* 		2. More recent. So, the specification has learnt from the mistakes of previous protocols
* 		3. Has a clean separation between audio & video (not muxed). Easy to play multilanguage audio
* 		4. It is codec-agnostic. In future, if you use a different codec, it will support it
* 		5. The manifest describes which codec is used
* 		6. Manifest can specify different codecs and let client decide which one to play
* 	9. DASH.js:
* 		1. Reference player for HTML5/Javascript
* 		2. It is a Media Source Extension Client
* 		3. It will playback the content via Media Source Extensions
* 		4. Has complexity baked in - For encrypted content (DRM). Playready for IE, Widevine for Chrome
* 		5. Has all the buffering and bitrate logic (Written in an extensible way)
* 	10. How to play a DASH stream:
* 		1. Download manifest
* 		2. Parse Manifest
* 		3. Determine optimal bandwidth for client
* 		4. Initialize for bandwidth
* 		5. Download Segment
* 		6. Hand segment to MSE
* 		7. Check bandwidth to determine if change is necessary
* 	11. DASH manifest (XML):
* 		1. Root contains one or more <Period>s: Describes a discrete chunk of content
* 		2. Usually we have two periods: One for main content, one for ad content
* 		3. Inside <Period> we have <AdaptationSet>s.
* 		4. Inside <AdaptationSet>: A series of representations of functionally equivalent content
* 		5. Usually we have two adaptation sets: one for audio, one for video
* 		6. Inside <AdaptationSet> we have <SegmentTemplate> & <Representation>s
* 		7. <SegmentTemplate>: It describes the media (pattern of segment file names)
* 			(Ex: Describes the audio with language & mimetype)
* 		8. <Representation>s: Each is of a particular bitrate for the same content (client can choose)
* 	12. DASH structure:
* 		1. Manifest (.mpd): XML file describing the segments
* 		2. Initialization file: Contains headers needed to decode bytes in segments
* 		3. Segment files: Contains playable media (0 to n video tracks, 0 to n audio tracks)
* 	13. Test dash.js at: http://reference.dashif.org/dash.js/v2.3.0/samples/dash-if-reference-player/index.html
* 	14. Dash.js > MediaPlayer.js: (Exposes the APIs)
* 		1. Exposes top level functions (play, pause, isLive, ABR quality, etc)
* 		2. Manifest URL and the HTML video object are passed to the Media Player
* 	15. Dash.js > Context.js: (Dependency injection)
* 		1. Dependency mapping for the stream player
* 		2. Context is passed into MediaPlayer so that it can use mappings for different player instances
* 	16. Dash.js > Stream.js:
* 		1. Loading & Refreshing the manifest
* 		2. Create SourceBuffers from MediaSource
* 		3. Respond to events from HTML Video object
* 		4. For live stream, the live edge is calculated and passed to the BufferController instances
*	17. It is hard to find live edge in dash: Spec assumes client and encoder are in sync all the time (untrue)
*		Dash.js had to solve the problem of finding the edge with some difficulty
*	18. Dash.js > ManifestLoader.js:
*		1. Responsible for loading manifest files
*		2. Returns the parsed manifest
*	19. Dash.js > FragmentLoader.js:
*		1. Responsible for loading fragments
*		2. Loads requests sequentially
*	20. Dash.js > AbrController.js:
*		1. Responsible for deciding if current playback quality needs to be changed
*		2. Stream metrics are passed to a set of "rules" (An array, that will help choose what to play)
*			a. A rule based on bandwidth
*			b. A rule based on how fast buffer is filling up, etc
*		3. Set of rules is run through before requesting any segment
*		4. Methods:
*			a. getPlaybackQuality(type, data). type: Type of audio/video. data: The stream data.
*	21. Dash.js > DashContext.js:
*		1. Defines dependencies mapping specific to dash package
*			a. Parser (DashParser.js)
*			b. Index Handler (DashHandler.js)
*			c. Manifest extensions
*	22. Dash Flow: 
*		1. Create Context and MediaPlayer instances:
*			const context = new Dash.di.DashContext()
*			const player = new MediaPlayer(context)
*		2. Initialize MediaPlayer and set manifest URL:
*			player.startup()
*			player.setIsLive(false)
*			player.attachSource(manifest_url)
*		3. Attach HTML Video element:
*			video = document.querySelector('.dash-video-player video')
*			player.autoplay = true
*			player.attachView(video)
